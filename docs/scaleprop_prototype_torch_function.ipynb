{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aAoSgjO1FhVr"
      },
      "outputs": [],
      "source": [
        "from types import MethodWrapperType, GetSetDescriptorType\n",
        "from typing import *\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "from torch import Tensor, tensor, nn\n",
        "from icecream import ic\n",
        "\n",
        "def numeric_info(dtype):\n",
        "  return torch.finfo(dtype) if dtype.is_floating_point else torch.iinfo(dtype)\n",
        "\n",
        "def dtype_max(dtype):\n",
        "  return numeric_info(dtype).max\n",
        "\n",
        "def _round(x : Tensor, dtype : torch.dtype) -> Tensor:\n",
        "  \"\"\"\n",
        "  Convert to dtype, rounding if the destination is integer\n",
        "  \"\"\"\n",
        "  if dtype.is_floating_point:\n",
        "    return x.to(dtype)\n",
        "  else:\n",
        "    return torch.round(x).to(dtype)\n",
        "\n",
        "def function_str(func):\n",
        "  # https://stackoverflow.com/questions/251464/how-to-get-a-function-name-as-a-string\n",
        "  # for future expansion e.g. properties\n",
        "  if hasattr(func, '__module__'):\n",
        "    return func.__module__ + '.' + func.__qualname__\n",
        "  else:\n",
        "    return func.__qualname__\n",
        "\n",
        "def _uptype(dtype) -> torch.dtype:\n",
        "    \"\"\"\n",
        "    For DTYPE, what is the type in which most arithmetic (e.g. max, abs) is defined?\n",
        "    \"\"\"\n",
        "    GPU = False # Check more accurately, and choose bf16 as appropriate\n",
        "    f16_t = torch.float16 if GPU else torch.float32\n",
        "    map = {\n",
        "        torch.int8: torch.int16,\n",
        "        torch.int16: torch.int16,\n",
        "        torch.float8_e4m3fn: f16_t,\n",
        "        torch.float8_e5m2: f16_t,\n",
        "        torch.float16: f16_t,\n",
        "        torch.float32: torch.float32,\n",
        "    }\n",
        "    return map[dtype]\n",
        "\n",
        "def _to_uptype(t : Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Convert t to its _uptype\n",
        "    \"\"\"\n",
        "    return torch.as_tensor(t, dtype=_uptype(t.dtype))\n",
        "\n",
        "\n",
        "def _maxval(t : Tensor):\n",
        "    \"\"\"\n",
        "    Max absolute value of tensor, returned in its `_uptype`\n",
        "    \"\"\"\n",
        "    return _to_uptype(t).abs().max()\n",
        "\n",
        "torch.set_printoptions(precision=3, threshold=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(100x300) 10^-9 x Quants{-6.477|-0.451|-0.031|-0.000|0.026|8.470}\n",
            "Tensor(100x300) Quants{-0.064|-0.004|-0.000|0.000|0.000|0.063}\n",
            "Tensor(100x300) Quants{-0.540|-0.045|-0.003|0.000|0.003|0.675}\n",
            "Tensor(100x300) Quants{-8.183|-0.450|-0.033|0.000|0.026|6.499}\n",
            "Tensor(100x300) Quants{-66.096|-4.401|-0.295|0.000|0.274|54.166}\n",
            "Tensor(100x300) Quants{-733.743|-44.196|-3.178|0.000|2.708|756.593}\n",
            "Tensor(100x300) Quants{-6929.309|-445.872|-31.348|0.000|26.406|9162.788}\n",
            "Tensor(100x300) 10^4 x Quants{-5.667|-0.445|-0.030|-0.000|0.026|7.503}\n",
            "Tensor(100x300) 10^11 x Quants{-7.278|-0.433|-0.030|0.000|0.028|5.738}\n",
            "Tensor(100x300) Quants{-32675|-16383|-6741|8|6428|32687}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def tensor_oneline_str(t):\n",
        "  shape_str = \"x\".join(map(str, t.shape))\n",
        "  quantiles = torch.tensor([0, 0.05,.25, .5, .74, 1.0])\n",
        "  vals = torch.quantile(torch.flatten(t).to(torch.float32), quantiles)\n",
        "  if t.dtype.is_floating_point:\n",
        "    # scale down vals\n",
        "    max = torch.floor(torch.log10(vals.abs().max()))\n",
        "    if -2 <= max <= 3:\n",
        "      max = 0\n",
        "    max_scale = 10 ** -max\n",
        "    max_scale_str = f\"10^{int(max)} x \" if max != 0 else \"\"\n",
        "    vals_str = max_scale_str + \"Quants{\" + \"|\".join(f'{v:.3f}' for v in vals*max_scale) + \"}\"\n",
        "  else:\n",
        "    # Assume integer, print as integers\n",
        "    vals_str = \"Quants{\" + \"|\".join(f'{int(v)}' for v in vals) + \"}\"\n",
        "\n",
        "  classname = type(t).__name__\n",
        "\n",
        "  return f'{classname}({shape_str}) {vals_str}'\n",
        "\n",
        "for scale in [-10, -3, -2, -1, 0, 1, 2, 3, 10]:\n",
        "  kurt = 3\n",
        "  print(tensor_oneline_str(torch.randn(100,300)**kurt*(10**scale)))\n",
        "\n",
        "print(tensor_oneline_str((torch.randn(100,300) * 10000).to(torch.int16)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Core functionality, no syntactic sugar\n",
        "\n",
        "Define a `ScaleTensorData` object, with the minimal information, and with operations\n",
        "defined cleanly, but without PyTorch Tensor integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM8RBHPwIkV2",
        "outputId": "353862f6-c2e3-4346-b891-25de11eb3550"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float16)\n",
            "tensor([1., 2., 3.], dtype=torch.float8_e4m3fn)\n",
            "ScaledTensor(0.0066964286379516125 * Tensor(3) Quants{144.000|158.400|216.000|288.000|364.800|448.000})\n",
            "wasted_bits(st_data.data)=tensor(0.023) <-- of a max of 8 bits, should be wasting nearly zero\n",
            "ScaledTensor(0.0066964286379516125 * Tensor(3) Quants{144.000|158.400|216.000|288.000|364.800|448.000})\n",
            "tensor([0.964, 1.928, 3.000], dtype=torch.float16) # <- rounding errors at the high end of the f8 range\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class ScaledTensorData:\n",
        "    data: Tensor\n",
        "    scale: Tensor\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        if not isinstance(self.scale, Tensor):\n",
        "            self.scale = tensor(self.scale)\n",
        "        assert self.scale.dtype == torch.float32\n",
        "        assert self.scale.shape == () \n",
        "        # Possible future expansion to e.g. row-scaled, column-scaled, etc, but\n",
        "        # for now, insist st_scale is a single-element tensor\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"ScaledTensor({self.scale} * {tensor_oneline_str(self.data)})\"\n",
        "\n",
        "    def to_tensor(self, dtype: torch.dtype) -> Tensor:\n",
        "        return self.data.to(dtype) * self.scale.to(dtype)\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> torch.Size:\n",
        "        return self.data.shape\n",
        "    \n",
        "    @property\n",
        "    def dtype_max(self):\n",
        "        return dtype_max(self.data.dtype)\n",
        "\n",
        "def st_quantise(x: Tensor, dtype: torch.dtype) -> ScaledTensorData:\n",
        "    \"\"\"\n",
        "    Rescale so that max(|data|) == maxFinite(data.dtype)\n",
        "\n",
        "    \"\"\"\n",
        "    maxval = _maxval(x)\n",
        "    if maxval == 0:\n",
        "        # Tensor is all zeros - set scale to 1\n",
        "        scale = Tensor(1.0, dtype=torch.float32)\n",
        "    else:\n",
        "        # Scale so that largest element is the largest finite value of dtype\n",
        "        scale = maxval / dtype_max(dtype)\n",
        "\n",
        "    return ScaledTensorData(_round(x / scale, dtype), scale)\n",
        "\n",
        "\n",
        "def st_requantise(st: ScaledTensorData) -> ScaledTensorData:\n",
        "    \"\"\"\n",
        "    Rescale so that max(|data|) == maxFinite(data.dtype)\n",
        "\n",
        "    Equivalent to quantise(st.to_tensor(torch.float32)) but avoids the conversion\n",
        "\n",
        "    Returned tensor may share its data with input tensor\n",
        "    \"\"\"\n",
        "    maxdataval = _maxval(st.data)\n",
        "    if maxdataval == 0:\n",
        "        # All zero, reset scale to 1\n",
        "        return ScaledTensorData(st.data, st.scale)\n",
        "    else:\n",
        "         rescale = maxdataval / st.dtype_max\n",
        "    return ScaledTensorData((_to_uptype(st.data) * (1 / rescale)).to(st.data.dtype), st.scale * rescale)\n",
        "\n",
        "\n",
        "def wasted_bits(st_data, maxval = None) -> float:\n",
        "    \"\"\"\n",
        "    By how much is tensor `st_data` not using the full dynamic range of its dtype?\n",
        "\n",
        "    E.g.\n",
        "       t = torch.tensor([1,2,-16], dtype=torch.int8)\n",
        "\n",
        "    Is using only 5 (4 + sign) of the available 8 bits.\n",
        "    Therefore \n",
        "       wasted_bits(t) == 3 == 8-3\n",
        "\n",
        "    Optional argument maxval, if the maximum value in the tensor has already \n",
        "    been computed, perhaps with a higher-accuracy method (e.g. pre-rounding)\n",
        "    \"\"\"\n",
        "    if maxval is None:\n",
        "        maxval = _maxval(st_data)\n",
        "\n",
        "    maxval = maxval.to(st_data.dtype)\n",
        "    dtype_bits = numeric_info(st_data.dtype).bits\n",
        "    if maxval == 0:\n",
        "        # All values zero -> all bits are wasted\n",
        "        return dtype_bits\n",
        "    \n",
        "    # Otherwise, how many bits is maxval using.\n",
        "    if st_data.dtype.is_floating_point:\n",
        "      # Convert maxval to integer of the same bitwidth\n",
        "      ints = {\n",
        "          8: torch.int8,\n",
        "          16: torch.int16,\n",
        "          32: torch.int32\n",
        "      }\n",
        "      maxval = maxval.view(ints[dtype_bits])\n",
        "\n",
        "    # Assuming a signed type, max usable bits are dtype_bits-1\n",
        "    return dtype_bits-1 - torch.log2(maxval)\n",
        "\n",
        "def test_wasted_bits():\n",
        "    t = torch.tensor([1,2,-16], dtype=torch.int8)\n",
        "    assert wasted_bits(t) == 3\n",
        "test_wasted_bits()\n",
        "\n",
        "### Quick testing\n",
        "f16 = tensor([1, 2, 3], dtype=torch.float16)\n",
        "f8_t = torch.float8_e4m3fn\n",
        "print(f16)\n",
        "print(f16.to(f8_t))\n",
        "\n",
        "st_data = st_quantise(f16, f8_t)\n",
        "\n",
        "# TODO: wasting a lot more bits at the low end here -- range of 144->448.\n",
        "print(st_data)\n",
        "print(f'{wasted_bits(st_data.data)=} <-- of a max of {numeric_info(f8_t).bits} bits, should be wasting nearly zero')\n",
        "print(st_requantise(st_data))\n",
        "print(st_data.to_tensor(f16.dtype), \"# <- rounding errors at the high end of the f8 range\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Operators, without syntactic sugar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| st1: ScaledTensor(0.5 * Tensor() Quants{32|32|32|32|32|32})\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| st2: ScaledTensor(0.25 * Tensor() Quants{64|64|64|64|64|64})\n",
            "ic| st_add(st1, st2): ScaledTensor(0.75 * Tensor() Quants{42|42|42|42|42|42})\n",
            "ic| f32(st_add(st1, st2)): tensor(31.500)\n",
            "ic| f32(st1) + f32(st2): tensor(32.)\n",
            "ic| st3: ScaledTensor(0.024901721626520157 * Tensor(2x32) Quants{-89|-68|-29|5|33|127})\n",
            "ic| st4: ScaledTensor(0.02432318590581417 * Tensor(32x3) Quants{-115|-67|-19|4|34|127})\n",
            "ic| st_matmul(st3, st4): ScaledTensor(2.4615209102630615 * Tensor(2x3) Quants{-5|-4|-2|0|1|5})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "st_matmul: WARNING: Very bad maxval estimate 312.6131591796875 vs 13.816981315612793, 22.625286102294922x too large - will lose at least 4.678071975708008 bits of precision\n",
            "st_matmul: WARNING: Very bad maxval estimate 312.6131591796875 vs 13.816981315612793, 22.625286102294922x too large - will lose at least 4.678071975708008 bits of precision\n",
            "f32(st_matmul(st3, st4)) = tensor([[ -7.385,   0.000,   2.462],\n",
            "        [ 12.308,   2.462, -12.308]]) <-- quantized\n",
            "f32(st3) @ f32(st4) = tensor([[ -7.567,  -1.465,   3.374],\n",
            "        [ 13.817,   3.596, -13.120]]) <-- intermediate\n",
            "t3 @ t4 = tensor([[ -7.493,  -1.548,   3.283],\n",
            "        [ 13.791,   3.617, -13.126]]) <-- exact\n"
          ]
        }
      ],
      "source": [
        "# Ops\n",
        "# - Use worst-case scaling rules (no overflow!)\n",
        "# - Placeholder impl (fast impl requires custom kernels)\n",
        "# - No autograd support\n",
        "\n",
        "def st_add(a: ScaledTensorData, b: ScaledTensorData) -> ScaledTensorData:\n",
        "    out_dtype = a.data.dtype\n",
        "    scale = a.scale + b.scale\n",
        "    data = (_to_uptype(a.data) * (a.scale / scale) + _to_uptype(b.data) * (b.scale / scale)).to(out_dtype)\n",
        "    return ScaledTensorData(data, scale)\n",
        "\n",
        "\n",
        "def st_matmul(a: ScaledTensorData, b: ScaledTensorData, debug = True) -> ScaledTensorData:\n",
        "    assert a.data.dtype == b.data.dtype\n",
        "    in_dtype = a.data.dtype\n",
        "    out_dtype = a.data.dtype\n",
        "\n",
        "    a_maxval = a.scale * a.dtype_max\n",
        "    b_maxval = b.scale * b.dtype_max\n",
        "\n",
        "    # Predicted maxval for NxK @ KxM\n",
        "    K = a.shape[-1]\n",
        "    out_maxval_estimate = a_maxval * b_maxval * K\n",
        "\n",
        "    out_scale = out_maxval_estimate / dtype_max(out_dtype) \n",
        "\n",
        "    # Derivation of matmul scale factors:\n",
        "    # (ad * as) @ (bd * bs) = (ad @ bd) * (as * bs)\n",
        "    #                       = (ad @ bd) * (as * bs / os * os)\n",
        "    #                       = (ad @ bd * as * bs / os) * os\n",
        "    #                       = (ad @ bd * rat) * os\n",
        "    #                         where rat = as * bs / os\n",
        "    #                       = (ad * sqrt(rat)) @ (bd * sqrt(rat)) * os\n",
        "\n",
        "    rat = a.scale * b.scale / out_scale\n",
        "\n",
        "    if numeric_info(in_dtype).bits < numeric_info(_uptype(in_dtype)).bits:\n",
        "        # Assume low-precision muls will accumulate to uptype, so won't overflow\n",
        "        # to simulate this on cpu, uptype before the matmul;\n",
        "        # on appropriate hardware (e.g. graphcore, h100), call the special matmul\n",
        "        adbd = _to_uptype(a.data) @ _to_uptype(b.data)\n",
        "        if debug:\n",
        "            out_maxval = _maxval(adbd) * (a.scale * b.scale)\n",
        "        out_data = adbd * rat\n",
        "        out_data = out_data.to(out_dtype)\n",
        "    else:\n",
        "        # Inputs are in 16+ bits, and we know the products will certainly \n",
        "        # overflow, as they are scaled to dtype_max, so downscale before multiplying \n",
        "        sqrt_rat = torch.sqrt(rat)\n",
        "        a_down = _to_uptype(a.data) * sqrt_rat\n",
        "        b_down = _to_uptype(b.data) * sqrt_rat\n",
        "        out_data = a_down @ b_down\n",
        "        if debug:\n",
        "            out_maxval = _maxval(out_data) * out_scale\n",
        "        out_data = out_data.to(out_dtype)\n",
        "\n",
        "    # debug check how bad out_maxval_estimate was\n",
        "    if debug:\n",
        "        assert out_maxval_estimate > out_maxval # Should always be an upper bound\n",
        "        wasted = wasted_bits(out_data)\n",
        "        if wasted > numeric_info(out_dtype).bits/2:\n",
        "            print(f'st_matmul: WARNING: Very bad maxval estimate {out_maxval_estimate} vs {out_maxval}, {out_maxval_estimate/out_maxval}x too large - will lose at least {wasted} bits of precision')\n",
        "\n",
        "        if _maxval(out_data) == 0:\n",
        "            raise ValueError(\"All-data zero - rerun with debug and view st_matmul: WARNING above\")\n",
        "\n",
        "    return ScaledTensorData(out_data, out_scale)\n",
        "\n",
        "\n",
        "def st_relu(a: ScaledTensorData) -> ScaledTensorData:\n",
        "    data = nn.functional.relu(a.data).to(a.data.dtype)\n",
        "    return ScaledTensorData(data, a.scale)\n",
        "\n",
        "# Check operators behae sensibly\n",
        "st1 = ScaledTensorData(tensor(32, dtype=torch.int8), 0.5)\n",
        "st2 = ScaledTensorData(tensor(64, dtype=torch.int8), 0.25)\n",
        "\n",
        "f32 = lambda x: x.to_tensor(torch.float32) if isinstance(x, ScaledTensorData) else x.to(dtype=torch.float32)\n",
        "\n",
        "\n",
        "ic(st1)\n",
        "ic(st2)\n",
        "ic(st_add(st1, st2))\n",
        "ic(f32(st_add(st1, st2)) )\n",
        "ic(f32(st1) + f32(st2))\n",
        "\n",
        "hidden = 32\n",
        "t3 = torch.randn(2, hidden)\n",
        "t4 = torch.randn(hidden, 3)\n",
        "st3 = st_quantise(t3, torch.int8)\n",
        "st4 = st_quantise(t4, torch.int8)\n",
        "ic(st3)\n",
        "ic(st4)\n",
        "ic(st_matmul(st3, st4))\n",
        "print(f'{f32(st_matmul(st3, st4)) = } <-- quantized')\n",
        "print(f'{f32(st3) @ f32(st4) = } <-- intermediate')\n",
        "print(f'{t3 @ t4 = } <-- exact')\n",
        "\n",
        "# st5 = st_quantise(tensor([-2, 3, -0.06, 4]), torch.int8)\n",
        "# ic(st5, f32(st5))\n",
        "# rt5 = st_relu(st5)\n",
        "# ic(rt5, f32(rt5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "### [Aside: Possibly surprising rounding]\n",
        "\n",
        "# print('Starting point: ', tensor([-2, 0.09, 4]))\n",
        "\n",
        "# st5 = st_quantise(tensor([-2, 0.09, 4]), torch.int8)\n",
        "# print(f'{st5=} {f32(st5)=} <-- 0.0900 input rounds to 0.0630')\n",
        "\n",
        "# print('So, put in 0.0630 to begin with')\n",
        "# st5 = st_quantise(tensor([-2, 0.0630, 4]), torch.int8) \n",
        "# print(f'{st5=} {f32(st5)=} <-- great, 0.0630 rounds to 0.0630')\n",
        "\n",
        "# print('But now, put in 0.06')\n",
        "# st5 = st_quantise(tensor([-2, 0.06, 4]), torch.int8) \n",
        "# print(f'{st5=} {f32(st5)=} <-- Eh, 0.06 rounds down to 0.0315?')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sugar hit: override Tensor operations in subclass\n",
        "\n",
        "We define a `ScaledTensor` object that behaves like a torch Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float16)\n",
            "tensor([1, 2, 3], dtype=torch.int8)\n",
            "<ScaledTensor(nan) where nan=ScaledTensor(0.023622047156095505 * Tensor(3) Quants{42|46|63|85|105|127})>\n",
            "<ScaledTensor(nan) where nan=ScaledTensor(0.023622047156095505 * Tensor(3) Quants{42|46|63|85|105|127})>\n",
            "Rounding errors at the high end of the f8 range: tensor([0.992, 2.008, 3.000], dtype=torch.float16)\n",
            "Viewing as a tensor should show NaN: tensor(nan)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.T@(<class '__main__.ScaledTensor'>,)\n",
            "Reshaped, but upscaled to f32: tensor([0.992, 2.008, 3.000])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ScaledTensor(nan, requires_grad=True) where nan=ScaledTensor(0.023622047156095505 * Tensor(3) Quants{42|46|63|85|105|127})>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# See https://pytorch.org/docs/stable/notes/extending.html#extending-torch-with-a-tensor-like-type\n",
        "# TODO: check _make_wrapper_subclass\n",
        "class ScaledTensor(Tensor):\n",
        "    def __init__(self, st_data : ScaledTensorData):\n",
        "        super().__init__()\n",
        "        self.st = st_data\n",
        "        \n",
        "    def __new__(cls, st_data, *args, **kwargs):\n",
        "        # Ensure that if the tensor is ever viewed as the base class, it is NaN\n",
        "        tensor_data = tensor(torch.nan)\n",
        "        return super().__new__(cls, tensor_data, *args, **kwargs)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        # See https://github.com/pytorch/pytorch/issues/73665\n",
        "        with torch._C.DisableTorchFunctionSubclass():\n",
        "            return f\"<{super().__repr__()} where nan={self.st}>\"\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> torch.Size:\n",
        "        return self.st.shape\n",
        "\n",
        "    def size(self) -> torch.Size:\n",
        "        return self.st.shape\n",
        "\n",
        "    def requires_grad_(self, val):\n",
        "        with torch._C.DisableTorchFunctionSubclass():\n",
        "            return super().requires_grad_(val)\n",
        "            \n",
        "    def detach(self) -> Tensor:\n",
        "        return ScaledTensor(ScaledTensorData(self.st.data.detach(), self.st.scale))\n",
        "\n",
        "    @classmethod\n",
        "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
        "        kwargs = kwargs or {}\n",
        "        # Have we registered a handler?\n",
        "        # 1. Turn \"func\" into something we can lookup in the HANDLED_FUNCTIONS dict.\n",
        "        if isinstance(func, MethodWrapperType):\n",
        "            # For methods, e.g. Tensor.T, we want to use that name, so unpack it\n",
        "            assert func.__qualname__ == 'getset_descriptor.__get__' # This is the only case tested so far\n",
        "            func_to_lookup = func.__self__\n",
        "        else:\n",
        "            # Probably other special cases here\n",
        "            func_to_lookup = func\n",
        "\n",
        "        # 2. Is this one we handle?\n",
        "        if func_to_lookup in cls.HANDLED_FUNCTIONS:\n",
        "          ret = cls.HANDLED_FUNCTIONS[func_to_lookup](*args, **kwargs)\n",
        "          # handler may return \"NotImplemented\" to tell us to run the fallback\n",
        "          if ret != NotImplemented:\n",
        "              return ret\n",
        "          # Otherwise drop through to the fallback\n",
        "\n",
        "        # 3. Fallback: Convert to float32 and call func\n",
        "        print(f\"ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for {function_str(func_to_lookup)}@{types}\")\n",
        "\n",
        "        def to_tensor_if_scaled(t : Any) -> Tensor:\n",
        "            if isinstance(t, ScaledTensor):\n",
        "                return t.st.to_tensor(torch.float32)\n",
        "            else:\n",
        "                return t\n",
        "\n",
        "        new_args = tuple(to_tensor_if_scaled(a) for a in args)\n",
        "        new_kwargs = { k:to_tensor_if_scaled(v) for (k,v) in kwargs.items() }\n",
        "\n",
        "        # To call the default implementation, docs suggest we call\n",
        "        #    ret = super().__torch_function__(func, types, new_args, new_kwargs)\n",
        "        # but the super()'s handler will forcibly downcast the result to ScaledTensor\n",
        "        # which is wrong - they are not ScaledTensors.  Just return what was computed.\n",
        "        with torch._C.DisableTorchFunctionSubclass():\n",
        "            return func(*new_args, **new_kwargs)\n",
        "\n",
        "ScaledTensor.HANDLED_FUNCTIONS = {}\n",
        "\n",
        "# Forward the ScaledTensorData ops above on the ScaledTensor type\n",
        "def quantise(x: Tensor, dtype: torch.dtype) -> ScaledTensor:\n",
        "    return ScaledTensor(st_quantise(x, dtype))\n",
        "\n",
        "def requantise(st) -> ScaledTensor:\n",
        "    return ScaledTensor(st_requantise(st.st))\n",
        "\n",
        "# Check basic to/from Subclass\n",
        "f16 = tensor([1, 2, 3], dtype=torch.float16)\n",
        "f8_t = torch.int8\n",
        "print(f16)\n",
        "print(f16.to(f8_t))\n",
        "\n",
        "st = quantise(f16, f8_t)\n",
        "\n",
        "print(st)\n",
        "print(requantise(st))\n",
        "print('Rounding errors at the high end of the f8 range:', st.st.to_tensor(f16.dtype))\n",
        "print('Viewing as a tensor should show NaN:', Tensor(st))\n",
        "\n",
        "print('Reshaped, but upscaled to f32:', st.T)\n",
        "\n",
        "st.requires_grad_(True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now overrides work, but just punt up to f32 for all ops\n",
        "\n",
        "We will do some adds/multiplies etc, and note that the torch function\n",
        "implementation issues a sequence of \"WARNING: Upcasting to float32\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.add@(<class '__main__.ScaledTensor'>,)\n",
            "tensor([2.992, 4.008, 5.000])\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.mul@(<class '__main__.ScaledTensor'>,)\n",
            "tensor([1.984, 4.016, 6.000])\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.add@(<class '__main__.ScaledTensor'>,)\n",
            "tensor([1.984, 4.016, 6.000])\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.matmul@(<class '__main__.ScaledTensor'>,)\n",
            "f32(st3 @ st4)       = tensor([[60000., 60000., 60000., 60000.],\n",
            "        [60000., 60000., 60000., 60000.]]) <-- should be ~48200 quantized, but was done in f32 so exact\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.to@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.to@(<class '__main__.ScaledTensor'>,)\n",
            "f32(st3) @ f32(st4)  = tensor([[60000., 60000., 60000., 60000.],\n",
            "        [60000., 60000., 60000., 60000.]]) <-- 60000 exact\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.T@(<class '__main__.ScaledTensor'>,)\n",
            "Reshaped, but upscaled to f32: tensor([[0.992, 4.016],\n",
            "        [1.984, 5.008],\n",
            "        [3.024, 6.000]])\n"
          ]
        }
      ],
      "source": [
        "print(st + 2)\n",
        "print(2 * st)\n",
        "print(st + st)\n",
        "\n",
        "st3 = quantise(torch.full((2, 3), 100.0), torch.int8)\n",
        "st4 = quantise(torch.full((3, 4), 200.0), torch.int8)\n",
        "\n",
        "print(f'{f32(st3 @ st4)       = } <-- should be ~48200 quantized, but was done in f32 so exact')\n",
        "print(f'{f32(st3) @ f32(st4)  = } <-- 60000 exact')\n",
        "\n",
        "m16 = quantise(tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float16), f8_t)\n",
        "\n",
        "print('Reshaped, but upscaled to f32:', m16.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| st3: ScaledTensor(0.787401556968689 * Tensor(2x3) Quants{127|127|127|127|127|127})\n",
            "ic| st3.T: ScaledTensor(0.787401556968689 * Tensor(3x2) Quants{"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_TensorBase.T\n",
            "_TensorBase.flatten\n",
            "torch._VariableFunctionsClass.flatten\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127|127|127|127|127|127})\n",
            "ic| st3.flatten(): ScaledTensor(0.787401556968689 * Tensor(6) Quants{127|127|127|127|127|127})\n",
            "ic| torch.flatten(st3): ScaledTensor(0.787401556968689 * Tensor(6) Quants{127|127|127|127|127|127})\n",
            "ic| st4: ScaledTensor(1.574803113937378 * Tensor(3x4) Quants{127|127|127|127|127|127})\n",
            "ic| st3 @ st4: ScaledTensor(472.4409484863281 * Tensor(2x4) Quants{-45|-45|-45|-45|-45|-45})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f32(st3 @ st4)       = tensor([[-21259.842, -21259.842, -21259.842, -21259.842],\n",
            "        [-21259.842, -21259.842, -21259.842, -21259.842]]) <-- ~48200 quantized\n",
            "f32(st3) @ f32(st4)  = tensor([[60000., 60000., 60000., 60000.],\n",
            "        [60000., 60000., 60000., 60000.]]) <-- 60000 exact\n",
            "ScaledTensor(0.023622047156095505 * Tensor(3) Quants{42|46|63|85|105|127})\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.requires_grad_@(<class '__main__.ScaledTensor'>,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0.992, 2.008, 3.000], requires_grad=True)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def torch_function_override(cls, funcs):\n",
        "    funcs = funcs if isinstance(funcs, tuple) else (funcs,)\n",
        "\n",
        "    def doit(impl):\n",
        "        # This work is also done by functools.wraps, but it doesn't make sensible names,\n",
        "        # and doesn't fix qualname\n",
        "        if not hasattr(impl,\"__name__\"):\n",
        "            pass\n",
        "        else:\n",
        "          if impl.__name__ == '_':\n",
        "              impl.__name__ = f'@torch_function_override({cls.__name__}, {funcs})'\n",
        "              if impl.__qualname__ != '_':\n",
        "                  print(f'torch_function_override: NOTE: {impl.__qualname__} not overridden')\n",
        "          if impl.__qualname__ == '_':\n",
        "              impl.__qualname__ = f'torch_function_override({cls.__name__}, {funcs})'\n",
        "          else:\n",
        "              pass\n",
        "\n",
        "        # Record it in the dictionary\n",
        "        for func in funcs:\n",
        "          cls.HANDLED_FUNCTIONS[func] = impl\n",
        "\n",
        "    return doit\n",
        "\n",
        "@torch_function_override(ScaledTensor, Tensor.add)\n",
        "def _(a:Tensor, b: Tensor) -> Tensor:\n",
        "    if not (isinstance(a, ScaledTensor) and isinstance(b, ScaledTensor)):\n",
        "        print(f'ScaledTensor: Punting on {type(a), type(b)=}')\n",
        "        return NotImplemented\n",
        "\n",
        "    return ScaledTensor(st_add(a.st, b.st))\n",
        "\n",
        "@torch_function_override(ScaledTensor, Tensor.matmul)\n",
        "def _(a:Tensor, b: Tensor) -> Tensor:\n",
        "    if not (isinstance(a, ScaledTensor) and isinstance(b, ScaledTensor)):\n",
        "        return NotImplemented\n",
        "\n",
        "    return ScaledTensor(st_matmul(a.st, b.st))\n",
        "\n",
        "@torch_function_override(ScaledTensor, Tensor.to)\n",
        "def _(a:Tensor, dtype:torch.dtype) -> Tensor:\n",
        "    assert isinstance(a, ScaledTensor)\n",
        "    return a.st.to_tensor(dtype)\n",
        "\n",
        "@torch_function_override(ScaledTensor, (Tensor.relu, nn.functional.relu))\n",
        "def _(a:Tensor, inplace = False) -> Tensor:\n",
        "    assert isinstance(a, ScaledTensor)\n",
        "    assert not inplace\n",
        "    return ScaledTensor(st_relu(a.st))\n",
        "\n",
        "## Override reshaping operations\n",
        "def reshape_passthru(func, a:Tensor, *args, **kwargs) -> Tensor:\n",
        "    assert isinstance(a, ScaledTensor)\n",
        "    func_to_call = func.__get__ if isinstance(func, GetSetDescriptorType) else func\n",
        "    st_data = func_to_call(a.st.data, *args, **kwargs)\n",
        "    return ScaledTensor(ScaledTensorData(st_data, a.st.scale))\n",
        "\n",
        "for func in (Tensor.T, Tensor.flatten, torch.flatten):\n",
        "    print(function_str(func))\n",
        "    torch_function_override(ScaledTensor, func)(partial(reshape_passthru, func))\n",
        "\n",
        "ic(st3)\n",
        "ic(st3.T)\n",
        "ic(st3.flatten())\n",
        "ic(torch.flatten(st3))\n",
        "\n",
        "ic(st4)\n",
        "ic(st3 @ st4 )\n",
        "print(f'{f32(st3 @ st4)       = } <-- ~48200 quantized')\n",
        "print(f'{f32(st3) @ f32(st4)  = } <-- 60000 exact')\n",
        "\n",
        "print(nn.functional.relu(st))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# And in a network..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtrOg8FMpDb3",
        "outputId": "cd7bc783-0567-4c37-908d-56ba2ec2e1a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| self.W1: ScaledTensor(0.04146788641810417 * Tensor(4096x1024) Quants{-127|-40|-16|0|16|126})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "st_matmul: WARNING: Very bad maxval estimate 21791.580078125 vs 43.23326110839844, 504.046630859375x too large - will lose at least 8 bits of precision\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "All-data zero - rerun with debug and view st_matmul: WARNING above",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[19], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m module \u001b[38;5;241m=\u001b[39m FFN(hidden_size, storage_type)\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m quantise(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, hidden_size), storage_type)\n\u001b[0;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
            "File \u001b[0;32m~/micromamba/envs/scaledarith/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/micromamba/envs/scaledarith/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[19], line 13\u001b[0m, in \u001b[0;36mFFN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Union[Tensor, ScaledTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, ScaledTensor]:\n\u001b[0;32m---> 13\u001b[0m     y \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW0\u001b[49m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, ScaledTensor):\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwasted bits #1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwasted_bits(y)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[16], line 38\u001b[0m, in \u001b[0;36mScaledTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     func_to_lookup \u001b[38;5;241m=\u001b[39m func\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func_to_lookup \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mHANDLED_FUNCTIONS:\n\u001b[0;32m---> 38\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHANDLED_FUNCTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc_to_lookup\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m     40\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
            "Cell \u001b[0;32mIn[18], line 38\u001b[0m, in \u001b[0;36m_\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(a, ScaledTensor) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, ScaledTensor)):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ScaledTensor(\u001b[43mst_matmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mst\u001b[49m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[0;32mIn[14], line 65\u001b[0m, in \u001b[0;36mst_matmul\u001b[0;34m(a, b, debug)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mst_matmul: WARNING: Very bad maxval estimate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_maxval_estimate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_maxval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_maxval_estimate\u001b[38;5;241m/\u001b[39mout_maxval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mx too large - will lose at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwasted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bits of precision\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _maxval(out_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-data zero - rerun with debug and view st_matmul: WARNING above\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ScaledTensorData(out_data, out_scale)\n",
            "\u001b[0;31mValueError\u001b[0m: All-data zero - rerun with debug and view st_matmul: WARNING above"
          ]
        }
      ],
      "source": [
        "# Example\n",
        "from icecream import ic\n",
        "\n",
        "class FFN(nn.Module):\n",
        "    def __init__(self, hidden_size: int, dtype: torch.dtype):\n",
        "        super().__init__()\n",
        "        q = lambda x: quantise(x, dtype)\n",
        "        self.W0 = q(torch.randn(hidden_size, 4*hidden_size))\n",
        "        self.W1 = q(torch.randn(4*hidden_size, hidden_size))\n",
        "        ic(self.W1)\n",
        "\n",
        "    def forward(self, x: Union[Tensor, ScaledTensor]) -> Union[Tensor, ScaledTensor]:\n",
        "        y = nn.functional.relu(x @ self.W0)\n",
        "\n",
        "        if isinstance(y, ScaledTensor):\n",
        "            print(f\"wasted bits #1: {wasted_bits(y)}\")\n",
        "            y = requantise(y)\n",
        "\n",
        "        y = y @ self.W1\n",
        "\n",
        "        if isinstance(y, ScaledTensor):\n",
        "            print(f\"wasted bits #2: {wasted_bits(y)}\")\n",
        "\n",
        "        return y\n",
        "\n",
        "hidden_size = 1024\n",
        "storage_type = torch.int8\n",
        "module = FFN(hidden_size, storage_type)\n",
        "x = quantise(torch.randn(10, hidden_size), storage_type)\n",
        "result = module(x)\n",
        "print()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bird  deer  deer  deer \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight Parameter(6x3x5x5) Quants{-0.115|-0.106|-0.057|0.002|0.062|0.115}\n",
            "conv1.bias Parameter(6) Quants{-0.088|-0.071|-0.014|0.012|0.020|0.034}\n",
            "conv2.weight Parameter(16x6x5x5) Quants{-0.082|-0.073|-0.039|0.002|0.041|0.082}\n",
            "conv2.bias Parameter(16) Quants{-0.081|-0.072|-0.021|0.015|0.042|0.078}\n",
            "fc1.weight Parameter(120x400) Quants{-0.050|-0.045|-0.025|-0.000|0.024|0.050}\n",
            "fc1.bias Parameter(120) Quants{-0.050|-0.044|-0.028|-0.004|0.023|0.049}\n",
            "fc2.weight Parameter(84x120) Quants{-0.091|-0.082|-0.046|0.000|0.044|0.091}\n",
            "fc2.bias Parameter(84) Quants{-0.087|-0.079|-0.055|0.001|0.034|0.085}\n",
            "fc3.weight Parameter(10x84) Quants{-0.109|-0.096|-0.054|0.006|0.054|0.109}\n",
            "fc3.bias Parameter(10) Quants{-0.077|-0.050|0.019|0.065|0.084|0.102}\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad_fn@(<class '__main__.ScaledTensor'>,)\n",
            "\n",
            "Post quantisation\n",
            "=================\n",
            "conv1.weight <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(3.5216969536122633e-06 * Tensor(6x3x5x5) Quants{-32767|-29968|-16304|657|17566|32586})>\n",
            "conv1.bias <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(2.6793343295139493e-06 * Tensor(6) Quants{-32767|-26544|-5123|4419|7501|12840})>\n",
            "conv2.weight <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(2.4916298571042717e-06 * Tensor(16x6x5x5) Quants{-32767|-29201|-15627|763|16291|32756})>\n",
            "conv2.bias <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(2.4855139599821996e-06 * Tensor(16) Quants{-32767|-28873|-8481|6154|16898|31451})>\n",
            "fc1.weight <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(1.5259200836226228e-06 * Tensor(120x400) Quants{-32767|-29529|-16545|-79|15658|32764})>\n",
            "fc1.bias <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(1.521453100394865e-06 * Tensor(120) Quants{-32767|-29114|-18147|-2583|15244|32125})>\n",
            "fc2.weight <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(2.7857752229465405e-06 * Tensor(84x120) Quants{-32767|-29425|-16392|86|15674|32767})>\n",
            "fc2.bias <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(2.6536699806456454e-06 * Tensor(84) Quants{-32767|-29857|-20572|202|12905|32219})>\n",
            "fc3.weight <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(3.327199692648719e-06 * Tensor(10x84) Quants{-32767|-28859|-16168|1730|16288|32764})>\n",
            "fc3.bias <Parameter(ScaledTensor(nan, requires_grad=True)) where nan=ScaledTensor(3.100993126281537e-06 * Tensor(10) Quants{-24670|-16033|6033|20973|27114|32767})>\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "for n,p in net.named_parameters():\n",
        "  print(n,tensor_oneline_str(p))\n",
        "\n",
        "d = net.state_dict()\n",
        "for k in d:\n",
        "  d[k] = quantise(d[k], torch.int16)\n",
        "\n",
        "net.load_state_dict(d, assign=True)\n",
        "\n",
        "print()\n",
        "print(\"Post quantisation\")\n",
        "print(\"=================\")\n",
        "for n,p in net.named_parameters():\n",
        "  print(n,p)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.is_leaf@(<class '__main__.ScaledTensor'>,)\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for _TensorBase.grad@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for torch._VariableFunctionsClass.conv2d@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for torch._VariableFunctionsClass.conv2d@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for torch._C._nn.linear@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for torch._C._nn.linear@(<class '__main__.ScaledTensor'>,)\n",
            "ScaledTensor.__torch_function__: WARNING: Upcasting to float32 for torch._C._nn.linear@(<class '__main__.ScaledTensor'>,)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[61], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print statistics\u001b[39;00m\n",
            "File \u001b[0;32m~/micromamba/envs/scaledarith/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/micromamba/envs/scaledarith/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 0:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
