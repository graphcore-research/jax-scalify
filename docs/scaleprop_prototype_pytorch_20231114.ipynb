{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aAoSgjO1FhVr"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from typing import *\n",
    "\n",
    "_torch_tensor_to = torch.Tensor.to\n",
    "_torch_tensor = torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sM8RBHPwIkV2",
    "outputId": "353862f6-c2e3-4346-b891-25de11eb3550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stensor([1.0002443 2.0004885 3.       ], dtype=sfloat16)\n",
      "Wasted 4.0 bits\n",
      "stensor([1.5262516e-05 3.0525032e-05 4.5776367e-05], dtype=sfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ScaledDType:\n",
    "    name: str\n",
    "    dtype: torch.dtype\n",
    "    base_scale: float\n",
    "\n",
    "    def __init__(self, name: str, dtype: torch.dtype):\n",
    "        self.name = name\n",
    "        self.dtype = dtype\n",
    "        dmax = torch.finfo(dtype).max if dtype.is_floating_point else torch.iinfo(dtype).max\n",
    "        self.base_scale = 1 / dmax\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.name, self.dtype))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self.name\n",
    "\n",
    "    @property\n",
    "    def bits(self) -> float:\n",
    "        return torch.finfo(self.dtype).bits if self.dtype.is_floating_point else torch.iinfo(self.dtype).bits\n",
    "\n",
    "\n",
    "sfloat16 = ScaledDType(\"sfloat16\", torch.float16)\n",
    "sfloat8_e4m3fn = ScaledDType(\"sfloat8_e4m3fn\", torch.float8_e4m3fn)\n",
    "sfloat8_e5m2 = ScaledDType(\"sfloat8_e5m2\", torch.float8_e5m2)\n",
    "sint32 = ScaledDType(\"sint32\", torch.int32)\n",
    "sint16 = ScaledDType(\"sint16\", torch.int16)\n",
    "sint8 = ScaledDType(\"sint8\", torch.int8)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ScaledTensor:\n",
    "    data: Tensor\n",
    "    scale: Tensor\n",
    "    dtype: ScaledDType\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        assert self.data.dtype == self.dtype.dtype\n",
    "        assert self.scale.dtype == torch.float32\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"stensor({self.to(torch.float32).numpy()}, dtype={self.dtype})\"\n",
    "\n",
    "    def to(self, dtype: torch.dtype) -> Tensor:\n",
    "        return self.data.to(dtype) * self.scale.to(dtype) * self.dtype.base_scale\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> torch.Size:\n",
    "        return self.data.shape\n",
    "\n",
    "    @classmethod\n",
    "    def quantise(cls, x: Tensor, dtype: ScaledDType) -> \"ScaledTensor\":\n",
    "        scale = x.abs().max().to(torch.float32)\n",
    "        if scale == 0:\n",
    "            scale = torch.tensor(1, dtype=torch.float32)\n",
    "        return cls(data=(x / scale / dtype.base_scale).to(dtype.dtype), scale=scale, dtype=dtype)\n",
    "\n",
    "    @property\n",
    "    def wasted_bits(self) -> float:\n",
    "        range = (self.data.abs().max() * self.dtype.base_scale).to(torch.float32)\n",
    "        if range == 0:\n",
    "            return self.dtype.bits\n",
    "        logrange = torch.log2(1 / range)\n",
    "        if self.dtype.dtype.is_floating_point:\n",
    "            return float(torch.log2(logrange))\n",
    "        return float(logrange)\n",
    "\n",
    "    def requantise(self) -> \"ScaledTensor\":\n",
    "        rescale = self.data.abs().max().to(torch.float32) * self.dtype.base_scale\n",
    "        return ScaledTensor((self.data / rescale).to(self.dtype.dtype), scale=self.scale * rescale, dtype=self.dtype)\n",
    "\n",
    "\n",
    "# Monkeypatch for convenience\n",
    "def _tensor_to(self: Tensor, *args: Any, **kwargs: Any) -> Tensor:\n",
    "    for arg in args + (kwargs.get(\"dtype\"),):\n",
    "        if isinstance(arg, ScaledDType):\n",
    "            assert len(args) + len(kwargs) == 1\n",
    "            return ScaledTensor.quantise(self, arg)\n",
    "    return _torch_tensor_to(self, *args, **kwargs)\n",
    "\n",
    "\n",
    "torch.Tensor.to = _tensor_to\n",
    "\n",
    "\n",
    "def _tensor(\n",
    "    data: Any, *, dtype: Union[None, torch.dtype, ScaledDType] = None, **kwargs: Any\n",
    ") -> Union[Tensor, ScaledTensor]:\n",
    "    if isinstance(dtype, ScaledDType):\n",
    "        return _torch_tensor(data, **kwargs).to(dtype)\n",
    "    return _torch_tensor(data, dtype=dtype, **kwargs)\n",
    "\n",
    "\n",
    "torch.tensor = _tensor\n",
    "\n",
    "d = torch.tensor([1, 2, 3], dtype=sfloat16)\n",
    "print(d)\n",
    "d.data[...] /= 2.0**16\n",
    "print(f\"Wasted {d.wasted_bits} bits\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylM9CdOGKpn2",
    "outputId": "9d4fa786-a6b2-4d04-aa23-3200a789588e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stensor(300.0, dtype=sint8)\n",
      "stensor([[390636.9 390636.9 390636.9]\n",
      " [390636.9 390636.9 390636.9]], dtype=sint16)\n"
     ]
    }
   ],
   "source": [
    "# Ops\n",
    "# - Use worst-case scaling rules (no overflow!)\n",
    "# - Placeholder impl (fast impl requires custom kernls)\n",
    "# - No autograd support\n",
    "\n",
    "\n",
    "def add(a: ScaledTensor, b: ScaledTensor) -> ScaledTensor:\n",
    "    assert a.dtype == b.dtype\n",
    "    scale = a.scale + b.scale\n",
    "    data = (a.data * (a.scale / scale) + b.data * (b.scale / scale)).to(a.data.dtype)\n",
    "    return ScaledTensor(data, scale, a.dtype)\n",
    "\n",
    "\n",
    "def matmul(a: ScaledTensor, b: ScaledTensor) -> ScaledTensor:\n",
    "    assert a.dtype == b.dtype\n",
    "    scale = a.scale * b.scale * a.shape[-1]\n",
    "    downscale = (a.shape[-1] / a.dtype.base_scale) ** -0.5\n",
    "    return ScaledTensor((a.data * downscale).to(a.dtype.dtype) @ (b.data * downscale).to(b.dtype.dtype), scale, a.dtype)\n",
    "\n",
    "\n",
    "def relu(a: ScaledTensor) -> ScaledTensor:\n",
    "    return ScaledTensor(nn.functional.relu(a.data), a.scale, a.dtype)\n",
    "\n",
    "\n",
    "ScaledTensor.__add__ = add\n",
    "ScaledTensor.__matmul__ = matmul\n",
    "\n",
    "\n",
    "print(torch.tensor(100, dtype=sint8) + torch.tensor(200, dtype=sint8))\n",
    "print(torch.full((2, 20), 100).to(sint16) @ torch.full((20, 3), 200).to(sint16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtrOg8FMpDb3",
    "outputId": "cd7bc783-0567-4c37-908d-56ba2ec2e1a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wasted bits #1: 8.167065620422363\n",
      "wasted bits #2: 10.912492752075195\n",
      "\n",
      "stensor([[ -94.06189   -47.030945 -470.30945  ...  -47.030945 -329.2166\n",
      "     0.      ]\n",
      " [  47.030945 -329.2166      0.       ...  235.15472   235.15472\n",
      "    94.06189 ]\n",
      " [  47.030945 -141.09283   -94.06189  ...    0.         47.030945\n",
      "   423.2785  ]\n",
      " ...\n",
      " [ -47.030945    0.         47.030945 ...  141.09283   188.12378\n",
      "   188.12378 ]\n",
      " [ 188.12378   188.12378  -235.15472  ...  -47.030945   47.030945\n",
      "   -94.06189 ]\n",
      " [  47.030945    0.       -141.09283  ...   47.030945 -376.24756\n",
      "     0.      ]], dtype=sint16)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, hidden_size: int, dtype: Union[torch.dtype, ScaledDType]):\n",
    "        super().__init__()\n",
    "        self.W0 = torch.randn(hidden_size, 4 * hidden_size).to(dtype)\n",
    "        self.W1 = torch.randn(4 * hidden_size, hidden_size).to(dtype)\n",
    "        self.relu = relu if isinstance(dtype, ScaledDType) else nn.functional.relu\n",
    "\n",
    "    def forward(self, x: Union[Tensor, ScaledTensor]) -> Union[Tensor, ScaledTensor]:\n",
    "        y = self.relu(x @ self.W0)\n",
    "\n",
    "        if isinstance(y, ScaledTensor):\n",
    "            print(f\"wasted bits #1: {y.wasted_bits}\")\n",
    "            y = y.requantise()\n",
    "\n",
    "        y = y @ self.W1\n",
    "\n",
    "        if isinstance(y, ScaledTensor):\n",
    "            print(f\"wasted bits #2: {y.wasted_bits}\")\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "hidden_size = 1024\n",
    "dtype = sint16\n",
    "module = FFN(hidden_size, dtype)\n",
    "result = module(torch.randn(10, hidden_size).to(dtype))\n",
    "print()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
