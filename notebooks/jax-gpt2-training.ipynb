{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1d7507-3dc6-4dbb-81e4-d64cf3edd516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6a141dc-8a6c-4cf6-a9a5-7f41ee29a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTParams:\n",
    "    num_seq: int\n",
    "    num_embd: int\n",
    "    num_head: int\n",
    "    num_layers: int\n",
    "\n",
    "    @property\n",
    "    def params_per_layer(self):\n",
    "        num_embd = self.num_embd\n",
    "        # QKV + projection + FFN\n",
    "        return (num_embd * num_embd) * (3 + 1 + 4 * 2)\n",
    "\n",
    "    def activation_size(self, batch_size, seq_len):\n",
    "        return batch_size * seq_len * self.num_embd\n",
    "\n",
    "    def matmul_output_activations(self, batch_size, seq_len):\n",
    "        # QKV + Attention + linear + FFN outputs\n",
    "        act_size = self.activation_size(batch_size, seq_len)\n",
    "        kv_attention_size = batch_size * seq_len * seq_len\n",
    "        ffn_size = 16 * act_size\n",
    "        return act_size * 3 + kv_attention_size + act_size + act_size + ffn_size + act_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5bbb95d6-7b48-4ffa-a4a1-800009f0519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 sizes: small, medium, large, XL\n",
    "# [\"124M\", \"355M\", \"774M\", \"1558M\"]\n",
    "\n",
    "gpt2_small = GPTParams(num_seq=128, num_embd=768, num_head=12, num_layers=12)\n",
    "gpt2_med = GPTParams(num_seq=128, num_embd=1024, num_head=16, num_layers=24)\n",
    "gpt2_large = GPTParams(num_seq=128, num_embd=1280, num_head=20, num_layers=36)\n",
    "gpt2_xl = GPTParams(num_seq=128, num_embd=1600, num_head=25, num_layers=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "582417d1-a897-4615-8d09-6a51c23f87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 XL\n",
    "n_seq = 128\n",
    "n_embd = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4dea009-f320-47d0-b9cf-72f771ae4397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.1072"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024 * 1600 * 8 / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4309674a-92cc-4cbb-9a2a-78345e934bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474.56"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_xl.params_per_layer * gpt2_xl.num_layers / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a5339f9-5acd-4cc4-ab80-d0d52cf987ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.16"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_per_ipu = 3\n",
    "layers_per_ipu * gpt2_xl.params_per_layer / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12bcb9ec-a05d-4113-bea8-32ae6af21a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2768"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_len = 128\n",
    "batch_size * gpt2_xl.num_embd * seq_len / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e19e2-34fd-47e0-86ac-bc01201ad56c",
   "metadata": {},
   "source": [
    "# Pipeline scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6209fd86-aadf-4e75-b76f-2454a81feb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT perc: 0.10666666666666667\n",
      "INTER perc: 2.3808\n",
      "ACT pipleine perc: 1.7066666666666668\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "seq_len = 128 * 4\n",
    "pipeline_size = 16\n",
    "\n",
    "params_per_ipu = gpt2_xl.params_per_layer\n",
    "print(\"ACT perc:\", gpt2_xl.activation_size(batch_size, seq_len) / params_per_ipu)\n",
    "print(\"INTER perc:\", gpt2_xl.matmul_output_activations(batch_size, seq_len) / params_per_ipu)\n",
    "print(\"ACT pipleine perc:\", gpt2_xl.activation_size(batch_size, seq_len) / params_per_ipu * pipeline_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7913fe6a-4dbe-4205-ae52-f32d840794a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
